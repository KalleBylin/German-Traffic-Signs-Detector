{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nqup8AeeQTwS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kalle\\Anaconda3\\envs\\german\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1860,
     "status": "ok",
     "timestamp": 1526665405372,
     "user": {
      "displayName": "Kalle Bylin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106403157380623395607"
     },
     "user_tz": 300
    },
    "id": "57lp0LrbetWJ",
    "outputId": "a30eb7f9-7cc1-4dba-8518-d2126e998ffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def load_img(path, size):\n",
    "    img = Image.open(path)\n",
    "    old_size = img.size\n",
    "\n",
    "    ratio = float(size/max(old_size))\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "    img = img.resize(new_size, Image.ANTIALIAS)\n",
    "    delta_w = size - new_size[0]\n",
    "    delta_h = size - new_size[1]\n",
    "    padding = (delta_w//2, delta_h//2, delta_w-(delta_w//2), delta_h-(delta_h//2))\n",
    "    img = ImageOps.expand(img, padding)\n",
    "    return np.array(img)\n",
    "    \n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "size = 28\n",
    "\n",
    "for j in range(43):\n",
    "    train_path = os.path.join('../images', 'train', str(j).rjust(2, '0'), '*.ppm')\n",
    "    files = glob.glob(train_path)\n",
    "    for file in files:\n",
    "        X_train.append(load_img(file, size))\n",
    "        y_train.append(j)\n",
    "        \n",
    "    test_path = os.path.join('../images', 'test', str(j).rjust(2, '0'), '*.ppm')\n",
    "    files = glob.glob(test_path)\n",
    "    for file in files:\n",
    "        X_test.append(load_img(file, size))\n",
    "        y_test.append(j)\n",
    "\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "y_test = np.array(y_test, dtype=np.float32)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22ed0b186d8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = Image.open('../images/train/00/00001.ppm')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 674,
     "status": "ok",
     "timestamp": 1526665406454,
     "user": {
      "displayName": "Kalle Bylin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106403157380623395607"
     },
     "user_tz": 300
    },
    "id": "MJZEw2affMeD",
    "outputId": "a2031a69-e033-491f-f155-5819cee27759"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773, 28, 28, 3)\n",
      "(440, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QaZ4WR3emURo"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y_train2 = enc.fit_transform(y_train.reshape(-1, 1)).toarray()\n",
    "y_test2 = enc.transform(y_test.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1526665412405,
     "user": {
      "displayName": "Kalle Bylin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106403157380623395607"
     },
     "user_tz": 300
    },
    "id": "Ft7uqzKZmZ0P",
    "outputId": "553481cd-8f46-4cb0-ca38-a4f38a9df6ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(773, 43)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-Based Learning with LeNet model\n",
    "\n",
    "**What is it?**\n",
    "\n",
    "Pattern recognition systems perform better when built relying more on automatic learning and less on hand-designed heuristics. Usually the system is divided into two partes. First a feature extractor, which transforms the input patterns so that yjey can be represented by low-dimensional vectors that can be easily compared and are relatively invariant to transformations and distortions of the input patterns that don't change their nature. Secondly, a classifier which is often general-purpose and trainable.\n",
    "\n",
    "To train this system, gradient-based learning is often used. A loss function  which compares the desired output with the predictions of the model is minimized with procedures like gradient descent. This is possible in non-linear systems with several layers of processing thanks to algorithms like back-propagation used to calculate gradients efficiently by propagation from the output to the input. \n",
    "\n",
    "\n",
    "A real-world example for logistic regression could be as a predictor for wether a patient has a disease, like diabetes, or not, based on certain characteristics of the patient like age, body mass index, sex, results tests, etc.\n",
    "\n",
    "**Strengths of the model**\n",
    "\n",
    "Multi-layer networks trained with gradient descent are capable to learn high-dimensional and non-linear mappings from large collections of examples. This makes them suitable for image recognition tasks.\n",
    "\n",
    "The LeNet model uses a specific architecture known as Convolutional Networks. This type of networks combines local receptive fields, shared weights and spatial/temporal sub-sampling to ensure a certain degree of invariance to shift, scale and distortion in the input. The local receptive fields allow the network to extract elementary visual features that are combined in following layers to detect higher-order features.\n",
    "\n",
    "Convolutional networks are particularly well suited for recognizing or rejecting shapes with widely varying size, position, and orientation.\n",
    "\n",
    "**Weaknesses of the model**\n",
    "\n",
    "This model also has it has its trade-offs and weaknesses. First of all, neural networks tend to be more computationally expensive and require large amounts of data to train. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qbYOCqLembFQ"
   },
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "lr = 0.0003\n",
    "num_classes = y_train2.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qJgtRdNTmehd"
   },
   "outputs": [],
   "source": [
    "def conv_layer(input_data, input_channels, filter_size, num_filters):\n",
    "    W = tf.Variable(tf.truncated_normal(shape=[filter_size, filter_size, input_channels, num_filters], stddev=0.05))\n",
    "    b = tf.Variable(tf.constant(0.05, shape=[num_filters]))\n",
    "    \n",
    "    layer = tf.nn.conv2d(input=input_data, filter=W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    layer += b\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def fully_connected(input_data, num_inputs, num_outputs):\n",
    "    W = tf.Variable(tf.truncated_normal([num_inputs, num_outputs], stddev=0.05))\n",
    "    b = tf.Variable(tf.constant(0.05, shape=[num_outputs]))\n",
    "    \n",
    "    return tf.matmul(input_data, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZdKxk6lWmiYP"
   },
   "outputs": [],
   "source": [
    "#Reset tensorflow graph\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1526665184410,
     "user": {
      "displayName": "Kalle Bylin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106403157380623395607"
     },
     "user_tz": 300
    },
    "id": "KeJmEj_Q1uz9",
    "outputId": "eb46da8a-ce04-4a51-a165-6e5919f00a30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 640,
     "status": "ok",
     "timestamp": 1526665435533,
     "user": {
      "displayName": "Kalle Bylin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106403157380623395607"
     },
     "user_tz": 300
    },
    "id": "kLZu4T1mmjtr",
    "outputId": "887cf076-dc2a-458b-c8b3-b11e54ad25c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (?, 28, 28, 3)\n",
      "C1: (?, 28, 28, 6)\n",
      "S2: (?, 14, 14, 6)\n",
      "A1: (?, 14, 14, 6)\n",
      "C3: (?, 14, 14, 16)\n",
      "S4: (?, 7, 7, 16)\n",
      "C5: (?, 7, 7, 120)\n",
      "F6: (?, 84)\n",
      "Output: (?, 43)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 28, 28, 3], name='x_input')\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_input')\n",
    "\n",
    "print('Input:', x.get_shape())\n",
    "c1 = conv_layer(input_data=x, input_channels=3, filter_size=5, num_filters=6)\n",
    "# We choose a window_size of [1, 2, 2, 1] for a 2x2 window but 1 for batch and \n",
    "# channel dimensions because we don't want to take the maximum over multiple examples or channels\n",
    "print('C1:', c1.get_shape())\n",
    "s2 = tf.nn.pool(input=c1, window_shape=[2, 2], pooling_type='AVG', padding='SAME', strides=[2,2])\n",
    "print('S2:', s2.get_shape())\n",
    "a1 = tf.nn.relu(s2)\n",
    "print('A1:', a1.get_shape())\n",
    "\n",
    "c3 = conv_layer(input_data=a1, input_channels=6, filter_size=5, num_filters=16)\n",
    "print('C3:', c3.get_shape())\n",
    "s4 = tf.nn.pool(input=c3, window_shape=[2, 2], pooling_type='AVG', padding='SAME', strides=[2,2])\n",
    "print('S4:', s4.get_shape())\n",
    "a2 = tf.nn.relu(s4)\n",
    "\n",
    "c5 = conv_layer(input_data=a2, input_channels=16, filter_size=5, num_filters=120)\n",
    "print('C5:', c5.get_shape())\n",
    "\n",
    "num_features = c5.get_shape()[1:4].num_elements()\n",
    "flat = tf.reshape(c5, [-1, num_features])\n",
    "f6 = fully_connected(input_data=flat, num_inputs=num_features, num_outputs=84)\n",
    "print('F6:', f6.get_shape())\n",
    "a3 = tf.nn.relu(f6)\n",
    "\n",
    "output = fully_connected(input_data=a3, num_inputs=84, num_outputs=num_classes)\n",
    "print('Output:', output.get_shape())\n",
    "\n",
    "with tf.name_scope('Output'):\n",
    "    y = tf.nn.softmax(output)\n",
    "\n",
    "with tf.name_scope(\"Loss\"):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y))\n",
    "with tf.name_scope(\"declaring_gradient_descent\"):\n",
    "    # optimizer\n",
    "    # we use gradient descent for our optimizer \n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(loss)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zQYeOeOjmoXl"
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Accuracy'):\n",
    "    prediction = tf.argmax(y, 1, name='predict')\n",
    "    correct = tf.equal(prediction, tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name='accuracy')\n",
    "    \n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7eiXs0Nfmt0j"
   },
   "outputs": [],
   "source": [
    "loss_hist = []\n",
    "train_accs = []\n",
    "test_accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 572112,
     "status": "ok",
     "timestamp": 1526666375528,
     "user": {
      "displayName": "Kalle Bylin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106403157380623395607"
     },
     "user_tz": 300
    },
    "id": "knzW0xEZmqoV",
    "outputId": "1599ff8c-aa53-4c79-88c1-b116ddcb5e54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training accuracy: 0.045738045\n",
      "Test accuracy: 0.035856575\n",
      "Epoch 2000\n",
      "Training accuracy: 0.62785864\n",
      "Test accuracy: 0.58964145\n",
      "Epoch 4000\n",
      "Training accuracy: 0.6902287\n",
      "Test accuracy: 0.64143425\n",
      "Epoch 6000\n",
      "Training accuracy: 0.77858627\n",
      "Test accuracy: 0.7171315\n",
      "Epoch 8000\n",
      "Training accuracy: 0.80457383\n",
      "Test accuracy: 0.76494026\n",
      "Training finished\n",
      "Accuracy: 0.8366534\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        _, loss = sess.run([optimizer, cost], feed_dict = {x: X_train, y_: y_train2})\n",
    "        \n",
    "        acc = sess.run(accuracy, feed_dict = {x: X_train, y_: y_train2})\n",
    "        test_acc = sess.run(accuracy, feed_dict = {x: X_test, y_: y_test2})\n",
    "        \n",
    "        loss_hist.append(loss)\n",
    "        train_accs.append(acc)\n",
    "        test_accs.append(test_acc)\n",
    "        \n",
    "        if epoch % 2000 == 0:\n",
    "            print('Epoch', epoch)\n",
    "            print('Training accuracy:', acc)\n",
    "            print('Test accuracy:', test_acc)\n",
    "    print('Training finished')\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Accuracy:', accuracy.eval({x: X_test, y_: y_test2}))\n",
    "    \n",
    "    saver.save(sess, './model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ParNtJCuSj6I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "Copy of model3.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
